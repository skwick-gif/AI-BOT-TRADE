<div dir="rtl">

# 🤖 מדריך לשונית ה־AI Chat

מסמך זה נועד להסביר את לשונית ה־AI Chat באפליקציה, מטרותיה, אופן השימוש, וההבד## 🚧 פתרון תקלות נפוצות

- **"Perplexity API key not configured"**: יש להגדיר `PERPLEXITY_API_KEY` בקובץ `.env` ולהפעיל מחדש.
- **"invalid_model"**: החליפו מודל בתיבת הבחירה; אם נשמר מודל לא נתמך, המערכת תנסה מודל חלופי אוטומטית.
- **זמן תגובה ארוך (מעל 10 שניות)**: 
  - בחרו מודל מהיר יותר (`sonar` במקום `reasoning-pro`)
  - קצרו את השאלות
  - בדקו חיבור האינטרנט
- **שגיאות Timeout**: המערכת מגבילה זמן המתנה ל-30 שניות - אם עבר הזמן, תוצג שגיאה.
- **כפתור Send חסום**: אם הכפתור נתקע על "Thinking...", נסו לרענן את היישום.ין המודלים הזמינים של Perplexity.

---

## 🎯 מטרת הלשונית

לשונית ה־AI Chat מספקת ממשק שיחה עם עוזר חכם המתמחה בתחומי השוק הפיננסי, פורטפוליו, ניתוח טכני ופונדמנטלי, רעיונות מסחר, ומדיניות ניהול סיכונים. ניתן לשאול שאלות כלליות, לבצע בדיקות מהירות, ולקבל תובנות מותאמות להקשר שלך (כאשר מידע על הפורטפוליו זמין).

---

## 🧭 מבנה הלשונית

- **שדה קלט ו־Send**: שולחים הודעה לעוזר ומקבלים מענה.
- **כפתור "Test API"**: בודק אם ה־API של Perplexity זמין ומאומת (מפתח תקף וחיבור תקין) וגם מציג את זמן התגובה.
- **סטטוס API**: מציג האם החיבור תקין ואת המודל הפעיל (למשל: `API: OK (reasoning-pro)`).
- **בחירת מודל (Model Selector)**: תיבה לבחירת המודל הפעיל לשיחות. הבחירה נשמרת אוטומטית לקובץ `.env`.
- **כפתורי פעולה מהירה**: ארבעה כפתורים למשימות נפוצות:
  - 📊 Portfolio Status - סטטוס תיק השקעות
  - 📈 Market Update - עדכון שוק נוכחי  
  - 🎯 Trading Help - עזרה במסחר
  - ⚠️ Risk Analysis - ניתוח סיכונים

**טיפ**: ככל שהקשר קצר יותר (פחות נתונים/בקשות), זמן התגובה יהיה קצר יותר. המערכת מודדת ומציגה זמני תגובה אוטומטית.

---

## ⚙️ כיצד זה עובד מאחורי הקלעים

1. **Worker בתהליך רקע**: הלשונית יוצרת worker שמטפל בבקשות ה־AI, כך שה־UI נשאר חלק ולא נתקע.
2. **API של Perplexity**: הבקשות נשלחות ל־Perplexity בתצורת API OpenAI-compatible.
3. **מודל חלופי אוטומטי**: אם מוגדר מודל שאינו נתמך, מתבצע ניסיון נפילה אוטומטי למודל `sonar`.
4. **מעקב ביצועים**: המערכת מודדת ומתעדת:
   - זמן עיבוד כולל (מקבלת ההודעה עד התגובה)
   - זמן קריאת API נטו (רק התקשורת עם Perplexity)
   - פירוט בלוגים לניתוח ביצועים
5. **התראות אוטומטיות**: אם התגובה לוקחת מעל 3 שניות, מתווסף מידע על הזמן להודעה.

---

## 🧪 בדיקת חיבור (Test API)

- לחץ על "Test API". אם הכל תקין, תופיע הודעת  
  "✅ Perplexity API is working! Response time: X.XXs"  
  והסטטוס יצבע בירוק עם שם המודל.  
- המערכת מודדת ומציגה זמן תגובה מדויק לכל בדיקה.
- אם המפתח חסר/לא תקף או קיימת בעיית חיבור, תוצג הודעת שגיאה עם זמן הכשל.

**זמני תגובה צפויים**:
- 1-3 שניות: מצוין
- 3-7 שניות: טוב  
- 7+ שניות: אפשר לנסות מודל מהיר יותר

---

## 🧠 בחירת מודל והבדלים עיקריים

להלן סקירה תמציתית על מספר מודלים נפוצים של Perplexity (השמות עשויים להשתנות בהתאם למדיניות Perplexity):

- `reasoning-pro` (ברירת המחדל):
  - מיועד למשימות הדורשות נימוק עמוק, הסקת מסקנות ורכיבי שרשרת מחשבה.
  - עשוי להיות מעט איטי יותר אך נותן מענה אנליטי מעמיק יותר.
  - מתאים לשאלות מורכבות, הערכות סיכון וניתוחים מרובי שלבים.

- `sonar`:
  - מודל כללי ומהיר יחסית.
  - מתאים לשאלות קצרות ותשובות מהירות.
  - מומלץ כשחשובה תגובה זריזה ולא נדרש עומק מיוחד.

- `sonar-pro`:
  - גרסה חזקה יותר של sonar, עם דיוק/יכולות משופרות.
  - עשוי להיות מעט איטי יותר מ־sonar, אך מהיר מ־reasoning-pro.

- `sonar-small`:
  - דגם קל ומהיר במיוחד.
  - מתאים למשימות קצרות מאד, סיכומים מהירים או בדיקות תמציתיות.

הערות:
- לא כל המודלים זמינים לכל חשבון. אם מודל אינו נתמך, תוצג שגיאה והמערכת תנסה מודל חלופי.
- ניתן לשנות מודל בכל עת מתיבת הבחירה; הבחירה נשמרת אוטומטית.

---

## 💡 טיפים לשימוש יעיל

- **היו ממוקדים**: ניסוחים קצרים וברורים מניבים תגובות מהירות יותר.
- **העדיפו שאלות ספציפיות**: "נתח את AAPL בטווח 3–6 חודשים" עדיף על "מה דעתך על AAPL".
- **השתמשו בכפתורי הפעולה המהירה** למשימות נפוצות - הם מוכנים מראש ומהירים יותר.
- **עקבו אחר זמני התגובה**: המערכת מציגה זמן תגובה בלוגים ובהודעות ארוכות (מעל 3 שניות).
- **לבדיקות מהירות**, בחרו מודל מהיר (כמו `sonar`). **לניתוח מעמיק**, בחרו `reasoning-pro`.
- **הימנעו מהדבקת טקסטים גדולים** אם לא נדרש - זה מאט את התגובה.

---

## � על טוקנים (Tokens): מה זה, כמה ולמה

טוקנים הם יחידות הטקסט שהמודל קורא וכותב. כל בקשה מורכבת מ־2 חלקים:

- Prompt Tokens (קלט): המערכת, ההוראות, המסר שלך, ולעיתים הקשר (כמו תקציר פורטפוליו).
- Completion Tokens (פלט): הטקסט שהמודל מחזיר.

מה משפיע על הביצועים ומשך התגובה:
- יותר טוקנים בקלט ⇒ זמן עיבוד ארוך יותר.
- `PERPLEXITY_MAX_TOKENS` שולט על אורך הפלט המקסימלי (לא על הקלט), ברירת־המחדל באפליקציה: 2000.
- אם הקלט + הפלט המבוקש עולים על מגבלת המודל (context window), המודל יקצר/ידחה את הבקשה.

איך זה עובד אצלנו באפליקציה:
- אנו בונים Prompt קליל: הוראות מערכת קצרות + ההודעה שלך + הקשר מצומצם (למשל עד 5 אחזקות עיקריות, ללא משיכת מחירים חיה לפני הבקשה), כדי להפחית טוקנים ולשפר זמני תגובה.
- אפשר לשנות את גבול הפלט דרך `.env`:
  - `PERPLEXITY_MAX_TOKENS=1000` (דוגמה להקטנה) או `2000` (ברירת־מחדל). ערך גבוה = תשובות ארוכות יותר אך איטיות יותר.
- בחירת המודל (`PERPLEXITY_MODEL`) משפיעה על מגבלת הקשר (Context Window) והמהירות. מודלים מהירים (כמו `sonar`) נוטים להיות זריזים יותר; מודלים ריזונינג (כמו `reasoning-pro`) יספקו נימוק עמוק אך עלולים להיות איטיים יותר.

כללי אצבע שימושיים:
- קצרו את ההודעה והקשר למינימום הנדרש ⇒ תגובות מהירות יותר ופחות סיכוי לחרוג מהמגבלות.
- אם אתם צריכים תשובה קצרה, רגולטו גם את הבקשה: "ענה בתמצית עד 5 נקודות".
- אם מתקבלת שגיאה "too many tokens"/"invalid_request", נסו:
  - לקצר את ההודעה/להפחית הקשר.
  - לבחור מודל עם חלון הקשר גדול יותר (אם זמין) או להקטין `PERPLEXITY_MAX_TOKENS`.

הערכות פשוטות:
- בעברית/אנגלית, 1,000 תווים ≈ מאות טוקנים (היחס לא אחיד; תלוי בשפה ובמבנה הטקסט).
- כלל אצבע: 1 טוקן ≈ ~0.75 מילים באנגלית (בעברית/שפות אחרות היחס משתנה), לכן טקסט של 150–250 מילים עשוי להיות ~200–350 טוקנים.

שדרוגים אפשריים (אופציונלי):
- הפעלת Streaming (פיזור תגובה בזמן אמת) תשפר תחושת מהירות, אך לא משנה את צריכת הטוקנים הכוללת.
- מד טוקנים משוער לפני שליחה (אפשר להוסיף לכלי בעתיד במידת הצורך).

---

## �🧯 פתרון תקלות נפוצות

- "Perplexity API key not configured": יש להגדיר `PERPLEXITY_API_KEY` בקובץ `.env` ולהפעיל מחדש.
- "invalid_model": החליפו מודל בתיבת הבחירה; אם נשמר מודל לא נתמך, המערכת תנסה מודל חלופי.
- זמן תגובה ארוך: בחרו מודל מהיר יותר, קצרו את השאלות, או הפחיתו הקשר נוסף.

---

## 📁 היכן נשמרת ההגדרה

- **בחירת המודל** נשמרת ב־`.env` תחת `PERPLEXITY_MODEL`.
- **מגבלת טוקנים** נשמרת ב־`.env` תחת `PERPLEXITY_MAX_TOKENS` (ברירת מחדל: 2000).
- ניתן לערוך את הקובץ ידנית; שינוי דורש הפעלה מחדש כדי שייטען כברירת מחדל בפעם הבאה (אך שינוי מתוך הלשונית נכנס לתוקף מיידית).

## 📊 מעקב ביצועים ולוגים

המערכת מתעדת אוטומטית:
- **בטרמינל**: זמני תגובה מפורטים עבור כל פעולה
- **בצ'אט**: הודעות ארוכות (מעל 3 שניות) מכילות מידע על זמן התגובה
- **בסטטוס API**: מצב החיבור והמודל הפעיל

**דוגמה ללוג טיפיסי**:
```
2025-10-08 21:15:25 - AIService - INFO - Perplexity API call successful in 2.34s
2025-10-08 21:15:25 - ChatWidget - INFO - Total processing time: 2.45s
```

</div>
